{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c05aa3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\hp\\anaconda3\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from scikit-learn) (1.1.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from scikit-learn) (1.10.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from scikit-learn) (1.23.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "810c6732",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "508638fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn==1.1.3\n",
      "  Downloading scikit_learn-1.1.3-cp310-cp310-win_amd64.whl (7.5 MB)\n",
      "     ---------------------------------------- 7.5/7.5 MB 5.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from scikit-learn==1.1.3) (2.2.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from scikit-learn==1.1.3) (1.1.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from scikit-learn==1.1.3) (1.10.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from scikit-learn==1.1.3) (1.23.5)\n",
      "Installing collected packages: scikit-learn\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.2.2\n",
      "    Uninstalling scikit-learn-1.2.2:\n",
      "      Successfully uninstalled scikit-learn-1.2.2\n",
      "Successfully installed scikit-learn-1.1.3\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn==1.1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0136f9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn==1.2\n",
      "  Downloading scikit_learn-1.2.0-cp310-cp310-win_amd64.whl (8.2 MB)\n",
      "     ---------------------------------------- 8.2/8.2 MB 6.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from scikit-learn==1.2) (1.1.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from scikit-learn==1.2) (1.10.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from scikit-learn==1.2) (2.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from scikit-learn==1.2) (1.23.5)\n",
      "Installing collected packages: scikit-learn\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.1.3\n",
      "    Uninstalling scikit-learn-1.1.3:\n",
      "      Successfully uninstalled scikit-learn-1.1.3\n",
      "Successfully installed scikit-learn-1.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn==1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "49dd5d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn import datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "770966a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\n`load_boston` has been removed from scikit-learn since version 1.2.\n\nThe Boston housing prices dataset has an ethical problem: as\ninvestigated in [1], the authors of this dataset engineered a\nnon-invertible variable \"B\" assuming that racial self-segregation had a\npositive impact on house prices [2]. Furthermore the goal of the\nresearch that led to the creation of this dataset was to study the\nimpact of air quality but it did not give adequate demonstration of the\nvalidity of this assumption.\n\nThe scikit-learn maintainers therefore strongly discourage the use of\nthis dataset unless the purpose of the code is to study and educate\nabout ethical issues in data science and machine learning.\n\nIn this special case, you can fetch the dataset from the original\nsource::\n\n    import pandas as pd\n    import numpy as np\n\n    data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n    raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n    data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n    target = raw_df.values[1::2, 2]\n\nAlternative datasets include the California housing dataset and the\nAmes housing dataset. You can load the datasets as follows::\n\n    from sklearn.datasets import fetch_california_housing\n    housing = fetch_california_housing()\n\nfor the California housing dataset and::\n\n    from sklearn.datasets import fetch_openml\n    housing = fetch_openml(name=\"house_prices\", as_frame=True)\n\nfor the Ames housing dataset.\n\n[1] M Carlisle.\n\"Racist data destruction?\"\n<https://medium.com/@docintangible/racist-data-destruction-113e3eff54a8>\n\n[2] Harrison Jr, David, and Daniel L. Rubinfeld.\n\"Hedonic housing prices and the demand for clean air.\"\nJournal of environmental economics and management 5.1 (1978): 81-102.\n<https://www.researchgate.net/publication/4974606_Hedonic_housing_prices_and_the_demand_for_clean_air>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[99], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m boston \u001b[38;5;241m=\u001b[39m \u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_boston\u001b[49m()\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(boston\u001b[38;5;241m.\u001b[39mDESCR)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\datasets\\__init__.py:156\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload_boston\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    106\u001b[0m     msg \u001b[38;5;241m=\u001b[39m textwrap\u001b[38;5;241m.\u001b[39mdedent(\n\u001b[0;32m    107\u001b[0m         \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;124;03m        `load_boston` has been removed from scikit-learn since version 1.2.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;124;03m        \"\"\"\u001b[39;00m\n\u001b[0;32m    155\u001b[0m     )\n\u001b[1;32m--> 156\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m()[name]\n",
      "\u001b[1;31mImportError\u001b[0m: \n`load_boston` has been removed from scikit-learn since version 1.2.\n\nThe Boston housing prices dataset has an ethical problem: as\ninvestigated in [1], the authors of this dataset engineered a\nnon-invertible variable \"B\" assuming that racial self-segregation had a\npositive impact on house prices [2]. Furthermore the goal of the\nresearch that led to the creation of this dataset was to study the\nimpact of air quality but it did not give adequate demonstration of the\nvalidity of this assumption.\n\nThe scikit-learn maintainers therefore strongly discourage the use of\nthis dataset unless the purpose of the code is to study and educate\nabout ethical issues in data science and machine learning.\n\nIn this special case, you can fetch the dataset from the original\nsource::\n\n    import pandas as pd\n    import numpy as np\n\n    data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n    raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n    data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n    target = raw_df.values[1::2, 2]\n\nAlternative datasets include the California housing dataset and the\nAmes housing dataset. You can load the datasets as follows::\n\n    from sklearn.datasets import fetch_california_housing\n    housing = fetch_california_housing()\n\nfor the California housing dataset and::\n\n    from sklearn.datasets import fetch_openml\n    housing = fetch_openml(name=\"house_prices\", as_frame=True)\n\nfor the Ames housing dataset.\n\n[1] M Carlisle.\n\"Racist data destruction?\"\n<https://medium.com/@docintangible/racist-data-destruction-113e3eff54a8>\n\n[2] Harrison Jr, David, and Daniel L. Rubinfeld.\n\"Hedonic housing prices and the demand for clean air.\"\nJournal of environmental economics and management 5.1 (1978): 81-102.\n<https://www.researchgate.net/publication/4974606_Hedonic_housing_prices_and_the_demand_for_clean_air>\n"
     ]
    }
   ],
   "source": [
    "boston = datasets.load_boston()\n",
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7ee7fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6212a43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7fc12c4",
   "metadata": {},
   "source": [
    "## Q1: Save the dataset into pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838afb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e777fa",
   "metadata": {},
   "source": [
    "## Q2: Use different histograms to plot features that have right, left and zero skew."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87eaee74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f24a9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcb61b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15794b7f",
   "metadata": {},
   "source": [
    "## Q3: Prove your previous result using mean, median and mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e84f87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6853053",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f981e5f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91f8e019",
   "metadata": {},
   "source": [
    "## Q4: Use Skew function of Pandas to print skewness of each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ea244c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d4455a5",
   "metadata": {},
   "source": [
    "## Q5: Use numpy to draw normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4cebd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf7845ba",
   "metadata": {},
   "source": [
    "## Q6: Use numpy to draw uniform distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0882003",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c47173dd",
   "metadata": {},
   "source": [
    "## Q7: Use numpy to draw binomial distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714935f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6030f2ae",
   "metadata": {},
   "source": [
    "## Q8: Simulate Two Coin Flips, then draw the result distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772409a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5275dbfd",
   "metadata": {},
   "source": [
    "## Q9: Summary of Descriptive Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee1e893",
   "metadata": {},
   "source": [
    "1. Using scipy.stats\n",
    "- nobs: the number of observations or elements in your dataset\n",
    "- minmax: the tuple with the minimum and maximum values of your dataset\n",
    "- mean: the mean of your dataset\n",
    "- variance: the variance of your dataset\n",
    "- skewness: the skewness of your dataset\n",
    "- kurtosis: the kurtosis of your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09596d49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03194c30",
   "metadata": {},
   "source": [
    "2. method .describe()\n",
    "- count: the number of elements in your dataset\n",
    "- mean: the mean of your dataset\n",
    "- std: the standard deviation of your dataset\n",
    "- min and max: the minimum and maximum values of your dataset\n",
    "- 25%, 50%, and 75%: the quartiles of your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3834b7e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c54aca0e",
   "metadata": {},
   "source": [
    "# Q9: Summarize the differences between the Z-test and the T-test in three sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f10021",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "881945c0",
   "metadata": {},
   "source": [
    "## Calculate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f9af83",
   "metadata": {},
   "source": [
    "Let's assume that a class's average score is higher than 70 with a standard deviation of 10.\n",
    "Calculate the Z-value to determine whether there is sufficient data to support this claim at a 0.05 \n",
    "significance level if a sample of 50 students was chosen and their mean score was 80."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57964d62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a137a23",
   "metadata": {},
   "source": [
    "An establishment wants to boost sales. According to past sales data, each sale made by 30 salesmen averaged \n",
    "40 dollar. The most recent data indicated that an average sale per transaction was 60 dollar after some training.Find the t-value for a 20 dollar standard deviation. Did a training program increase sales?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712b063b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
